{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EU AI Act readiness\n",
    "Overview of risk categories, obligations, and documentation practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "from datetime import datetime, timedelta, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "- Classify systems: prohibited, high-risk, limited-risk, minimal-risk.\n",
    "- Know high-risk requirements: risk management, data governance, technical documentation, logging, transparency, human oversight, robustness, and cybersecurity.\n",
    "- Draft minimal documentation for a high-risk system.\n",
    "- Map overlaps and tensions with GDPR (legal basis, fairness, transparency).\n",
    "\n",
    "### Why this matters\n",
    "The EU AI Act introduces a **risk-based approach**: the higher the risk to fundamental rights or safety, the stricter the obligations. Understanding these categories is crucial for compliance planning. Many systems will be \"minimal risk\" (e.g., spam filters), while high-risk systems (e.g., hiring, medical, credit) face heavier obligations.\n",
    "\n",
    "> Educational material only. Always verify requirements against the latest consolidated text, guidance, and delegated acts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk ladder\n",
    "- **Prohibited:** manipulative subliminal techniques causing harm, social scoring by public authorities, exploitation of vulnerabilities.\n",
    "- **High-risk:** safety components (e.g., medical devices), critical infrastructure, employment/education, essential private/public services, law enforcement (under conditions), migration/asylum, justice.\n",
    "- **Limited-risk:** systems with transparency duties (e.g., chatbots disclosed as AI, emotion recognition with notice).\n",
    "- **Minimal-risk:** most other use cases; follow voluntary codes and good practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick reference\n",
    "- **Risk levels:**\n",
    "    - **Unacceptable risk:** banned (e.g., social scoring, subliminal manipulation).\n",
    "    - **High-risk:** strict obligations (e.g., medical devices, recruitment, critical infrastructure).\n",
    "    - **Limited risk:** transparency obligations (e.g., chatbots disclosed as AI).\n",
    "    - **Minimal risk:** no new obligations for most use cases (e.g., spam filters, video games).\n",
    "- **Key roles:** Provider (developer), Deployer (user), Importer, Distributor.\n",
    "- **Penalties:** depending on the infringement, fines can reach the higher of a fixed amount (e.g., €35M) or a percentage of global turnover (e.g., 7%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da93578",
   "metadata": {},
   "source": [
    "## High-risk obligations checklist\n",
    "1.  **Risk Management System:** Continuous iterative process.\n",
    "2.  **Data Governance:** Bias mitigation, representativeness.\n",
    "3.  **Technical Documentation:** Full details for conformity assessment.\n",
    "4.  **Record Keeping (Logging):** Traceability of system functioning.\n",
    "5.  **Transparency:** Instructions for use, accuracy metrics.\n",
    "6.  **Human Oversight:** Tools for human intervention.\n",
    "7.  **Accuracy, Robustness, Cybersecurity:** Resilient to errors and attacks.\n",
    "The code snippets below show concrete examples of applying these obligations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea02e393",
   "metadata": {},
   "source": [
    "## Main AI Act Articles (Reference)\n",
    "- **Prohibited Practices:** Art 5.\n",
    "- **High-Risk Classification:** Art 6 & Annex III.\n",
    "- **Data Governance:** Art 10 (Training, validation, testing data).\n",
    "- **Technical Documentation:** Art 11 & Annex IV.\n",
    "- **Transparency:** Art 13 (Instructions for use).\n",
    "- **Human Oversight:** Art 14.\n",
    "- **Accuracy, Robustness, Cybersecurity:** Art 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick classification exercise\n",
    "Describe a system below and classify it. Note why it is or is not high-risk, and what obligations apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- System Classification Card ---\n",
      "NAME: AI system for candidate ranking in hiring\n",
      "PROVIDER: HR-Tech-Solutions Inc.\n",
      "DEPLOYER: Global Corp\n",
      "RISK_LEVEL: high\n",
      "WHY: employment use case (Annex III)\n",
      "OBLIGATIONS:\n",
      "  - bias testing and representativeness checks (Art 10)\n",
      "  - logging and traceability (Art 12)\n",
      "  - human oversight on final decisions (Art 14)\n",
      "  - transparency notice to candidates (Art 13)\n",
      "  - cybersecurity robustness (Art 15)\n"
     ]
    }
   ],
   "source": [
    "scenario = {\n",
    "    'name': 'AI system for candidate ranking in hiring',\n",
    "    'provider': 'HR-Tech-Solutions Inc.',\n",
    "    'deployer': 'Global Corp',\n",
    "    'risk_level': 'high',\n",
    "    'why': 'employment use case (Annex III)',\n",
    "    'obligations': [\n",
    "        'bias testing and representativeness checks (Art 10)',\n",
    "        'logging and traceability (Art 12)',\n",
    "        'human oversight on final decisions (Art 14)',\n",
    "        'transparency notice to candidates (Art 13)',\n",
    "        'cybersecurity robustness (Art 15)'\n",
    "    ]\n",
    "}\n",
    "print(\"--- System Classification Card ---\")\n",
    "for k, v in scenario.items():\n",
    "    if isinstance(v, list):\n",
    "        print(f\"{k.upper()}:\")\n",
    "        for item in v:\n",
    "            print(f\"  - {item}\")\n",
    "    else:\n",
    "        print(f\"{k.upper()}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383319eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Governance Audit: gender ---\n",
      "Total Records: 8\n",
      "  M          | ||||||||||||         | 62.5%\n",
      "  F          | |||||                | 25.0%\n",
      "  NB         | ||                   | 12.5%\n",
      "\n",
      "[OK] Balance looks acceptable for this small sample.\n"
     ]
    }
   ],
   "source": [
    "# Data Governance: Check for bias/imbalance\n",
    "# Expanded dataset\n",
    "training_data = [\n",
    "    {'id': 1, 'gender': 'M', 'hired': True},\n",
    "    {'id': 2, 'gender': 'M', 'hired': False},\n",
    "    {'id': 3, 'gender': 'M', 'hired': True},\n",
    "    {'id': 4, 'gender': 'F', 'hired': False},\n",
    "    {'id': 5, 'gender': 'M', 'hired': True},\n",
    "    {'id': 6, 'gender': 'F', 'hired': True},\n",
    "    {'id': 7, 'gender': 'M', 'hired': False},\n",
    "    {'id': 8, 'gender': 'NB', 'hired': False},\n",
    "]\n",
    "\n",
    "def check_representativeness(data, sensitive_attr):\n",
    "    counts = {}\n",
    "    for row in data:\n",
    "        val = row.get(sensitive_attr, 'Unknown')\n",
    "        counts[val] = counts.get(val, 0) + 1\n",
    "    \n",
    "    total = len(data)\n",
    "    print(f\"--- Data Governance Audit: {sensitive_attr} ---\")\n",
    "    print(f\"Total Records: {total}\")\n",
    "    \n",
    "    for k, v in counts.items():\n",
    "        pct = v/total\n",
    "        # Using ASCII block for visualization\n",
    "        bar = \"|\" * int(pct * 20)\n",
    "        print(f\"  {k:<10} | {bar:<20} | {pct:.1%}\")\n",
    "        \n",
    "    # Simple heuristic for warning\n",
    "    if max(counts.values()) / total > 0.7:\n",
    "        print(\"\\n[WARNING] Significant imbalance detected. One group dominates >70% of data.\")\n",
    "        print(\"   Action required: Collect more diverse data or apply re-sampling.\")\n",
    "    else:\n",
    "        print(\"\\n[OK] Balance looks acceptable for this small sample.\")\n",
    "        \n",
    "check_representativeness(training_data, 'gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181cbf21",
   "metadata": {},
   "source": [
    "**What this code does:** Runs a simple representativeness/imbalance check by counting how many samples fall into each group (here: `gender`).\n",
    "It prints a bar chart-like view and warns if one group dominates more than 70% of the dataset (a very rough heuristic for Article 10-style data governance checks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fa91f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning features: ['candidate_ranking', 'emotion_recognition_workplace', 'automated_interview']\n",
      "\n",
      "[RED FLAG] System contains PROHIBITED practices:\n",
      "  - Art 5(1)(f) - Emotion recognition in workplace/education\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PROHIBITED'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prohibited Practices Check\n",
    "def check_prohibited(features: list) -> str:\n",
    "    prohibited_keywords = {\n",
    "        'subliminal': 'Art 5(1)(a) - Subliminal techniques',\n",
    "        'social_scoring': 'Art 5(1)(c) - Social scoring by public authorities',\n",
    "        'biometric_categorization_sensitive': 'Art 5(1)(h) - Biometric categorization (race, politics, etc.)',\n",
    "        'emotion_recognition_workplace': 'Art 5(1)(f) - Emotion recognition in workplace/education',\n",
    "        'exploitation_vulnerable': 'Art 5(1)(b) - Exploitation of vulnerable groups'\n",
    "    }\n",
    "    \n",
    "    print(f\"Scanning features: {features}\")\n",
    "    violations = []\n",
    "    for f in features:\n",
    "        if f in prohibited_keywords:\n",
    "            violations.append(prohibited_keywords[f])\n",
    "            \n",
    "    if violations:\n",
    "        print(\"\\n[RED FLAG] System contains PROHIBITED practices:\")\n",
    "        for v in violations:\n",
    "            print(f\"  - {v}\")\n",
    "        return \"PROHIBITED\"\n",
    "    else:\n",
    "        print(\"\\n[PASS] No prohibited features detected based on keywords.\")\n",
    "        return \"PERMITTED\"\n",
    "\n",
    "check_prohibited(['candidate_ranking', 'emotion_recognition_workplace', 'automated_interview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8588af7",
   "metadata": {},
   "source": [
    "**What this code does:** Scans a list of system features for keywords that *might* indicate an Article 5 prohibited practice.\n",
    "This is a simplified demo: real assessments depend on how the system works in context, not just feature names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging example\n",
    "Trace decisions to support post-market monitoring and incident investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Audit Log (Total Entries: 3) ---\n",
      "[\n",
      "  {\n",
      "    \"timestamp\": \"2026-01-19T08:56:06.936291Z\",\n",
      "    \"event_id\": \"evt-0001\",\n",
      "    \"user_id\": \"cand-123\",\n",
      "    \"input_summary\": {\n",
      "      \"cv_length\": 2,\n",
      "      \"keywords\": 15\n",
      "    },\n",
      "    \"model_version\": \"v1.2.0\",\n",
      "    \"output\": {\n",
      "      \"score\": 0.71,\n",
      "      \"rank\": \"B\"\n",
      "    },\n",
      "    \"status\": \"success\"\n",
      "  },\n",
      "  {\n",
      "    \"timestamp\": \"2026-01-19T08:56:06.936315Z\",\n",
      "    \"event_id\": \"evt-0002\",\n",
      "    \"user_id\": \"cand-124\",\n",
      "    \"input_summary\": {\n",
      "      \"cv_length\": 5,\n",
      "      \"keywords\": 40\n",
      "    },\n",
      "    \"model_version\": \"v1.2.0\",\n",
      "    \"output\": {\n",
      "      \"score\": 0.92,\n",
      "      \"rank\": \"A\"\n",
      "    },\n",
      "    \"status\": \"success\"\n",
      "  },\n",
      "  {\n",
      "    \"timestamp\": \"2026-01-19T08:56:06.936332Z\",\n",
      "    \"event_id\": \"evt-0003\",\n",
      "    \"user_id\": \"cand-125\",\n",
      "    \"input_summary\": {\n",
      "      \"cv_length\": 1,\n",
      "      \"keywords\": 5\n",
      "    },\n",
      "    \"model_version\": \"v1.2.0\",\n",
      "    \"output\": {\n",
      "      \"score\": 0.33,\n",
      "      \"rank\": \"C\"\n",
      "    },\n",
      "    \"status\": \"success\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Logging example\n",
    "def log_decision(user_id, input_summary, model_version, output, store):\n",
    "    timestamp = datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z')\n",
    "    entry = {\n",
    "        'timestamp': timestamp,\n",
    "        'event_id': f\"evt-{len(store)+1:04d}\",\n",
    "        'user_id': user_id,\n",
    "        'input_summary': input_summary,\n",
    "        'model_version': model_version,\n",
    "        'output': output,\n",
    "        'status': 'success'\n",
    "    }\n",
    "    store.append(entry)\n",
    "\n",
    "audit_log = []\n",
    "# Simulate a few decisions\n",
    "log_decision('cand-123', {'cv_length': 2, 'keywords': 15}, 'v1.2.0', {'score': 0.71, 'rank': 'B'}, audit_log)\n",
    "log_decision('cand-124', {'cv_length': 5, 'keywords': 40}, 'v1.2.0', {'score': 0.92, 'rank': 'A'}, audit_log)\n",
    "log_decision('cand-125', {'cv_length': 1, 'keywords': 5}, 'v1.2.0', {'score': 0.33, 'rank': 'C'}, audit_log)\n",
    "\n",
    "print(f\"--- Audit Log (Total Entries: {len(audit_log)}) ---\")\n",
    "print(json.dumps(audit_log, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d610a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 'High-Risk / Prohibited / Limited?',\n",
       " 'reasoning': '...',\n",
       " 'key_obligations': ['Human Oversight (Art 14)', '...'],\n",
       " 'transparency_notice_needed': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your notes here\n",
    "aiact_analysis = {\n",
    "    'classification': 'High-Risk / Prohibited / Limited?',\n",
    "    'reasoning': '...',\n",
    "    'key_obligations': [\n",
    "        'Human Oversight (Art 14)',\n",
    "        '...'\n",
    "    ],\n",
    "    'transparency_notice_needed': True\n",
    "}\n",
    "aiact_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cde7a4",
   "metadata": {},
   "source": [
    "**What this code does:** A template to capture your system classification and a draft compliance plan (what applies, why, and what you need to implement)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d3bd6",
   "metadata": {},
   "source": [
    "## Mini-case: Classify and comply\n",
    "- **System:** A \"Smart Proctoring\" tool for universities that uses webcam video to detect \"suspicious behavior\" (gaze tracking, background noise) and flags students for potential exam termination.\n",
    "- **Task:**\n",
    "    1. Is this high-risk? (Check Annex III — education).\n",
    "    2. Is it prohibited? (Check Article 5 — biometric categorization / emotion recognition?).\n",
    "    3. What obligations apply? (Transparency, accuracy, human oversight).\n",
    "Document your reasoning below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc46dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ================================================================\n",
      "                       SYSTEM TRANSPARENCY NOTICE                    \n",
      "    ================================================================\n",
      "     SYSTEM:    RecruitAI-v1                                \n",
      "     PROVIDER:  HR-Tech-Solutions Inc.                      \n",
      "    ----------------------------------------------------------------\n",
      "     PURPOSE:                                                       \n",
      "     Assist in ranking CVs based on keyword matching                \n",
      "    ----------------------------------------------------------------\n",
      "     PERFORMANCE:                                                   \n",
      "     85% on test set B (demographically balanced)                   \n",
      "    ----------------------------------------------------------------\n",
      "     [!] LIMITATIONS:                                                \n",
      "     Not valid for executive roles or creative portfolios           \n",
      "    ----------------------------------------------------------------\n",
      "     [O] HUMAN OVERSIGHT:                                            \n",
      "     Human recruiter must verify all rejections before sending emails \n",
      "    ================================================================\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Transparency: Instructions for Use\n",
    "system_metadata = {\n",
    "    'name': 'RecruitAI-v1',\n",
    "    'provider': 'HR-Tech-Solutions Inc.',\n",
    "    'purpose': 'Assist in ranking CVs based on keyword matching',\n",
    "    'accuracy': '85% on test set B (demographically balanced)',\n",
    "    'limitations': 'Not valid for executive roles or creative portfolios',\n",
    "    'human_oversight': 'Human recruiter must verify all rejections before sending emails'\n",
    "}\n",
    "\n",
    "def generate_notice(meta):\n",
    "    return f\"\"\"\n",
    "    ================================================================\n",
    "                       SYSTEM TRANSPARENCY NOTICE                    \n",
    "    ================================================================\n",
    "     SYSTEM:    {meta['name']:<43} \n",
    "     PROVIDER:  {meta['provider']:<43} \n",
    "    ----------------------------------------------------------------\n",
    "     PURPOSE:                                                       \n",
    "     {meta['purpose']:<62} \n",
    "    ----------------------------------------------------------------\n",
    "     PERFORMANCE:                                                   \n",
    "     {meta['accuracy']:<62} \n",
    "    ----------------------------------------------------------------\n",
    "     [!] LIMITATIONS:                                                \n",
    "     {meta['limitations']:<62} \n",
    "    ----------------------------------------------------------------\n",
    "     [O] HUMAN OVERSIGHT:                                            \n",
    "     {meta['human_oversight']:<62} \n",
    "    ================================================================\n",
    "    \"\"\"\n",
    "print(generate_notice(system_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc9dcd2",
   "metadata": {},
   "source": [
    "**What this code does:** Generates a transparency notice (Article 13) for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1) Replace the scenario with your own and classify it.\n",
    "2) Extend `log_decision` with a minimal retention policy (e.g., drop entries older than N days).\n",
    "3) Draft a one-page technical documentation outline: purpose, data, models, metrics, foreseeable risks, contact point.\n",
    "4) Note how GDPR applies: lawful basis, transparency, data subject rights, and if a DPIA is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2e798",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "The following cells contain example solutions for the exercises above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb031a",
   "metadata": {},
   "source": [
    "### Solution 1: Mini-case classification\n",
    "\n",
    "**System:** \"Smart Proctoring\" tool (webcam analysis for suspicious behavior).\n",
    "\n",
    "1.  **Classification:** **High-risk**.\n",
    "    *   **Reasoning:** It falls under Annex III, paragraph 3 (education and vocational training), specifically systems used for assessing students.\n",
    "2.  **Prohibited?**\n",
    "    *   **Check:** Does it use \"emotion recognition\"? If it infers emotional states (stress, anxiety) to determine cheating, it might be prohibited in education under Article 5(1)(f). If it only tracks gaze/movement, it is likely high-risk but not prohibited.\n",
    "3.  **Obligations:**\n",
    "    *   **Transparency:** Students must know they are being monitored and how the system flags behavior.\n",
    "    *   **Accuracy:** Validate to reduce false positives (e.g., looking away to think flagged as cheating).\n",
    "    *   **Human oversight:** The system should *flag* for review, not automatically terminate the exam. A human should make the final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e497fe6",
   "metadata": {},
   "source": [
    "### Solution 2: Logging with a retention policy\n",
    "\n",
    "We extend the log function to remove old entries after a defined retention period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a0a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAINTENANCE] Removed 1 old log entries.\n",
      "Current log size: 1\n"
     ]
    }
   ],
   "source": [
    "def log_decision_with_retention(user_id, input_summary, model_version, output, store, retention_days=30):\n",
    "    # 1. Add new entry\n",
    "    timestamp = datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z')\n",
    "    entry = {\n",
    "        'timestamp': timestamp,\n",
    "        'user_id': user_id,\n",
    "        'input': input_summary,\n",
    "        'output': output\n",
    "    }\n",
    "    store.append(entry)\n",
    "    \n",
    "    # 2. Apply retention (cleanup)\n",
    "    cutoff = datetime.now(timezone.utc) - timedelta(days=retention_days)\n",
    "    \n",
    "    # Filter list to keep only recent logs\n",
    "    # In a real DB, this would be a DELETE query\n",
    "    original_count = len(store)\n",
    "    store[:] = [\n",
    "        log for log in store\n",
    "        if datetime.fromisoformat(log['timestamp'].replace('Z', '+00:00')) > cutoff\n",
    "    ]\n",
    "    removed = original_count - len(store)\n",
    "    \n",
    "    if removed > 0:\n",
    "        print(f\"[MAINTENANCE] Removed {removed} old log entries.\")\n",
    "\n",
    "# Test it\n",
    "audit_store = []\n",
    "\n",
    "# Add an old entry manually\n",
    "old_timestamp = (datetime.now(timezone.utc) - timedelta(days=40)).isoformat().replace('+00:00', 'Z')\n",
    "audit_store.append({'timestamp': old_timestamp, 'data': 'old'})\n",
    "\n",
    "log_decision_with_retention('user-new', 'test', 'v1', 'result', audit_store, retention_days=30)\n",
    "print(f\"Current log size: {len(audit_store)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb723c",
   "metadata": {},
   "source": [
    "### Solution 3: Technical documentation outline\n",
    "\n",
    "For a high-risk system, Article 11 requires detailed documentation. A minimal outline includes:\n",
    "\n",
    "1.  **System description:**\n",
    "    *   Intended purpose (what does it do?).\n",
    "    *   Intended users (who uses it?).\n",
    "    *   Hardware/software requirements.\n",
    "2.  **Development process:**\n",
    "    *   **Data:** Source of training data, bias checks performed, data lineage.\n",
    "    *   **Model:** Architecture choice, training methodology, validation metrics (accuracy, F1-score).\n",
    "3.  **Risk management:**\n",
    "    *   List of foreseeable risks (e.g., bias against non-native speakers).\n",
    "    *   Mitigation measures (e.g., human-in-the-loop review).\n",
    "4.  **Monitoring:**\n",
    "    *   How the system is logged.\n",
    "    *   Post-market monitoring plan.\n",
    "\n",
    "---\n",
    "\n",
    "### Solution 4: GDPR overlaps\n",
    "\n",
    "The AI Act and GDPR complement each other:\n",
    "\n",
    "*   **Lawful basis (GDPR Article 6):** You still need a lawful basis (e.g., consent or legitimate interests) to process the *personal data* used to train or run the AI.\n",
    "*   **Automated decision-making (GDPR Article 22):** If the AI makes significant decisions without meaningful human involvement, GDPR provides a right to human review. The AI Act reinforces this via the \"human oversight\" requirement.\n",
    "*   **DPIA (GDPR Article 35):** A high-risk AI system will often require a data protection impact assessment (DPIA) because it can involve systematic and extensive evaluation of people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipm-GDPR-greendata-aiact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
